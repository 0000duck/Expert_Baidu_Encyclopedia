凌震华1979年8月出生于安徽省合肥市，毕业于，是专业博士。现任中国科学技术大学电子工程与信息科学系副教授、博士生导师。主要研究方向为语音信号处理。
2002年取得“”专业学士学位；2005年获得“”专业硕士学位；2008年获得“”专业博士学位；2007年10月至2008 年4 月，由Marie Curie Early Stage Training 项目支持，赴英国爱丁堡大学语音技术研究中心进行学术访问；2008年7月进入博士后流动站/博士后工作站从事博士后科研工作；2011年3月起任电子工程与信息科学系副教授。凌震华的主要研究领域包括语音合成、语音编码、声音转换等。先后作为主要技术人员参与“基于HMM模型的高表现力多语种语音合成技术”（国家863十一五专题课题）、“高表现力多语种韵律建模研究”（国家自然科学基金项目）、“多语言语音合成关键技术与应用产品开发”（国家863十一五重点项目子课题）等国家科研项目并承担核心研究工作。作为项目负责人承担的国家科研项目有 “基于合成语音质量评估的语音合成方法研究”(项目)和“结合发音动作参数的统计建模语音合成方法研究”（国家自然科学基金青年科学基金项目）。 凌震华在围绕语音合成的相关核心技术领域进行了近十年的深入研究，取得了一系列国际领先的研究成果，并对语音合成系统的实际性能提升与产业应用做出了积极贡献。完成发明专利申请7项（2项已获授权）；参与了IEEE Transactions on Audio Speech and Language Processing以及ICASSP/Interspeech/ISCSLP等语音信号处理领域主流国际学术期刊与会议的论文评审工作。在国内外学术期刊与会议上发表学术论文共40余篇，并获得2010年IEEE Signal Processing Society Young Author Best Paper Award。近五年发表的第一作者论文如下：[1] Zhen-Hua Ling, Zhi-Guo Wang, Li-Rong Dai, “Statistical Modeling of Syllable-Level F0 Features for HMM-based Unit Selection Speech Synthesis”, in Proc. of ISCSLP, pp. 144-147, 2010.[2] Zhen-Hua Ling, Yu Hu, and Li-Rong Dai, “Global Variance Modeling on the Log Power Spectrum of LSPs for HMM-based Speech Synthesis”, in Proc. of Interspeech, pp. 825-828, 2010.[3] Zhen-Hua Ling, Korin Richmond, and Junichi Yamagishi, “HMM-based Text-to-Articulatory-Movement Prediction and Analysis of Critical Articulators”, in Proc. of Interspeech, pp. 2194-2197, 2010.[4] Zhen-Hua Ling, Korin Richmond, and Junichi Yamagishi, “An analysis of HMM-based prediction of articulatory movements,” Speech Communication, vol. 52, no. 10, pp. 834-846, 2010.[5] Zhen-Hua Ling, Korin Richmond, Junichi Yamagishi, and Ren-Hua Wang, “Integrating articulatory features into HMM-based parametric speech synthesis,” IEEE Transaction on Audio, Speech, and Language Processing, vol. 17, no. 6, 2009, pp. 1171-1185.[6] Zhen-Hua Ling, Yu Hu, “An experimental study on the similarity performance of HMM-based parametric speech synthesis,” in Proc. of the 10th National Conference on Man-Machine Speech Communication, 2009.[7] 凌震华, 王仁华, “基于统计声学模型的单元挑选语音合成算法,” 模式识别与人工智能, vol. 21, no. 3, 2008, pp. 280-284.[8] Zhen-Hua Ling, Heng Lu, Guo-Ping Hu, Li-Rong Dai, and Ren-Hua Wang, “The USTC entry for Blizzard Challenge 2008,” in Proc. of Blizzard Challenge workshop, 2008.[9] Zhen-Hua Ling, Korin Richmond, Junichi Yamagishi, and Ren-Hua Wang, “Articulatory control of HMM-based parametric speech synthesis driven by phonetic knowledge,” in Proc. of Interspeech, 2008, pp. 573-576.[10] Zhen-Hua Ling, Wei Zhang, and Ren-Hua Wang, “Cross-stream dependency modeling for HMM-based speech synthesis,” in Proc. of ISCSLP, 2008, pp. 5-8.[11] Zhen-Hua Ling, and Ren-Hua Wang, “Minimum unit selection error training for HMM-based unit selection speech synthesis system,” in Proc. of ICASSP, pp. 3949-3952, 2008.[12] Zhen-Hua Ling, Long Qin, Heng Lu, Yu Gao, Li-Rong Dai, Ren-Hua Wang, Yuan Jiang, Zhi-Wei Zhao, Jin-Hui Yang, Jie Chen, and Guo-Ping Hu, “The USTC and iFlytek speech synthesis systems for Blizzard Challenge 2007,” in Proc. of Blizzard Challenge workshop, 2007.[13]　 Zhen-Hua Ling, and Ren-Hua Wang, “HMM-based hierarchical unit selection combining Kullback-Leibler divergence with likelihood criterion,” in Proc. of ICASSP, 2007, pp. 1245-1248.[14]　 Zhen-Hua Ling, Yi-Jian Wu, Yu-Ping Wang, Long Qin, and Ren-Hua Wang, “USTC system for Blizzard Challenge 2006 - an improved HMM-based speech synthesis method,” in Proc. of Blizzard Challenge workshop, 2006.[15] Zhen-Hua Ling, and Ren-Hua Wang, “HMM-based unit selection using frame sized speech segments,” in Proc. of Interspeech, 2006, pp. 2034-2037.中国科学技术大学信号与信息处理 中国科学技术大学电子信息工程中国科学技术大学信号与信息处理中国科学技术大学信号与信息处理中国科学技术大学安徽科大讯飞信息科技股份有限公司中国科学技术大学中国博士后科学基金